{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artskart Analytical Database\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "In this project I'm doing a query optimized analytical database of Redlisted Species in Norway with Artskart. Further, enrich data with population growth and deforestation. Artskart is a Citizen science project for recording species on maps into a national and freely accessible database. Artskart is owned by The Norwegian Biodiversity Information Centre. You may read more about Artskart here: https://www.biodiversity.no/Pages/135580/About_Norwegian_Biodiversity_Information_Centre?Key=1435226530\n",
    "\n",
    "The project follows the following steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pandas as pd\n",
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DateType, TimestampType\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scope \n",
    "I'm planning to do a query optimized analytical database of Redlisted Species in Norway. Further, enrich species data with population growth and deforestation. My primary datasource is Artskart, which is a Citizen science project for recording species on maps into a national and freely accessible database. Artskart is owned by The Norwegian Biodiversity Information Centre.\n",
    "- Explore and clean data using Apache Spark (PySpark) and validate that all data is in the expected format\n",
    "- Partition data into .csv files using PySpark and load them into a data lake in Amazon S3\n",
    "- Load data into an analytical datatabase in Postgres using parallell ETL with Python and AWS boto3 library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe and Gather Data \n",
    "Artskart2Index is a Microsoft SQL server relational datatabase where data is broken down into multiple different tables in 3NF.\n",
    "I'm using a pre-made view stored in the database's view folder to query redlisted species.\n",
    "I've restored the database on my local machine using `.bak-file` containing all species observation until the 7. march 2021. \n",
    "* Restore Artskart2Index database using the .bak-file and a local instance of SQL Server Express\n",
    "* Push down a query using Spark on a pre-processed database view fetching all redlisted species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SparkConf with native microsoft jdbc driver for sql-server\n",
    "configure = SparkConf().setAppName(\"Artskart\")\\\n",
    "                       .setMaster(\"local[*]\")\\\n",
    "                       .set(\"spark.driver.extraClassPath\",\"sqljdbc_9.2/enu/mssql-jdbc-9.2.1.jre8.jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SparkContext\n",
    "sc = SparkContext(conf = configure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database credentials\n",
    "jdbcHostname=<jdbcHostname>\n",
    "jdbcPort=<jdbcPort>\n",
    "jdbcDatabase=<jdbcDatabase>\n",
    "jdbcUsername=<jdbcUsername>\n",
    "jdbcPassword=<jdbcPassword>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JDBC connection URL\n",
    "jdbcUrl = \"jdbc:sqlserver://{0}:{1};Database={2};\".format(jdbcHostname, jdbcPort, jdbcDatabase)\n",
    "\n",
    "connectionProperties = {\n",
    "  \"user\" : jdbcUsername,\n",
    "  \"password\" : jdbcPassword,\n",
    "  \"driver\" : \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Artskart database\n",
    "pushdown_query = \"(select * from View_ShapeExportRedlist) redlist_alias\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[FID: int, ProxyId: string, NodeDatabaseID: int, InstitutionCode: string, CollectionCode: string, CatalogNumber: string, VitNavn: string, BasisOfRecord: string, Kingdom: string, Phylum: string, Class: string, Order: string, Family: string, Genus: string, Species: string, Subspecies: string, Author: string, IdentifiedBy: string, YearIdentified: int, MonthIdentified: int, DayIdentified: int, TypeStatus: string, CollectorNumber: string, FieldNumber: string, Collector: string, YearCollected: int, MonthCollected: int, DayCollected: int, ContinentOcean: string, Country: string, StateProvince: string, CountyOrg: string, Locality: string, CountyID: string, MunicipalityID: string, County: string, MuniName: string, Longitude: double, Latitude: double, CoordinatePrecision: int, BoundingBox: string, MinElevation: int, MaxElevation: int, MinDepth: string, MaxDepth: string, Sex: string, PreparationType: string, IndividualCount: string, PreviousCatalogNumber: string, RelationshipType: string, RelatedCatalogItem: string, Notes: string, CollectingMethod: string, IdentificationPrecision: int, NorskNavn: string, Okologi: string, Habitat: string, Substrat: string, UTMost: int, UTMnord: int, UTMsone: string, MGRSfra: string, MGRStil: string, UTM33ost: int, UTM33nord: int, KoordKilde: string, ElevationKilde: string, Status: string, RelativeAboundance: string, Antropokor: int, URL: string, ArtsGruppe: int, IName: string, CName: string, CategoryId: int]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Push down query \n",
    "# Read results into Spark dataframe\n",
    "df = spark.read.jdbc(url=jdbcUrl, table=pushdown_query, properties=connectionProperties)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Following error might occur when connecting with native JDBC driver\n",
    "`com.microsoft.sqlserver.jdbc.SQLServerException: The TCP/IP connection to the host HOSTNAME, port 1433 has failed.\n",
    "Error: \"Connection refused: connect. Verify the connection properties. Make sure that an instance of SQL Server is running on the host and accepting TCP/IP connections at the port.\n",
    "Make sure that TCP connections to the port are not blocked by a firewall.`\n",
    "\n",
    "Please read further here: https://kb.sos-berlin.com/pages/viewpage.action?pageId=17499564"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set filename\n",
    "file_name = \"redlist.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set output path to local working directory\n",
    "out_path = os.path.abspath(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a copy on my local working directory repartitioned by 8\n",
    "df.repartition(8).write.save(out_path, format=\"csv\", header=True) # row count: 4,384,290"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file back into RAM with Spark\n",
    "redlist = spark.read.csv(out_path, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(FID='41954328', ProxyId='urn:uuid:43688d2a-f87b-4031-9e20-c6e0ca85840a', NodeDatabaseID='1010', InstitutionCode='NOF', CollectionCode='so2-birds', CatalogNumber='24208745', VitNavn='Delichon urbicum', BasisOfRecord='humanobservation', Kingdom='Animalia', Phylum='Chordata', Class='Aves', Order='Passeriformes', Family='Hirundinidae', Genus='Delichon', Species='Delichon urbicum', Subspecies=None, Author='(Linnaeus, 1758)', IdentifiedBy=None, YearIdentified='0', MonthIdentified='0', DayIdentified='0', TypeStatus=None, CollectorNumber=None, FieldNumber=None, Collector='Frank Holmen', YearCollected='2020', MonthCollected='5', DayCollected='19', ContinentOcean=None, Country='Norway', StateProvince=None, CountyOrg=None, Locality='Møssevoll, Vessøyjordene, Grimstad, Ag', CountyID='42', MunicipalityID='4202', County='Agder', MuniName='Grimstad', Longitude='8.694183', Latitude='58.388015', CoordinatePrecision='116', BoundingBox=None, MinElevation=None, MaxElevation=None, MinDepth=None, MaxDepth=None, Sex=None, PreparationType=None, IndividualCount='3', PreviousCatalogNumber=None, RelationshipType=None, RelatedCatalogItem=None, Notes='Activity: Forage.', CollectingMethod=None, IdentificationPrecision='0', NorskNavn='taksvale', Okologi=None, Habitat=None, Substrat=None, UTMost='131645', UTMnord='6489200', UTMsone='33V', MGRSfra=None, MGRStil=None, UTM33ost='131645', UTM33nord='6489200', KoordKilde='OR', ElevationKilde=None, Status='NT', RelativeAboundance=None, Antropokor='0', URL='https://www.artsobservasjoner.no/Sighting/24208745', ArtsGruppe='8', IName='Norsk Ornitologisk Forening', CName='so2-birds hos Norsk Ornitologisk Forening', CategoryId='11')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redlist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy file to S3-bucket using AWS CLI\n",
    "!aws s3 out_path s3a://<bucket-name> --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![schematics](schematics.jpg \"schematics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the Data \n",
    "Identifying data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Questions to ask: \n",
    "- How many observations of redlisted species do we have in our dataset\n",
    "- Which redlisted specie were the most observed\n",
    "- Which redlisted specie were the least observed\n",
    "- How are the observations skeewed\n",
    "- Do we have any duplicates rows\n",
    "- Are there any corrupt rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4384290"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many observations of redlisted species do we have?\n",
    "redlist.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Do we have any duplicate rows?\n",
    "duplicates = redlist.count() - redlist.distinct().count()\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(County='Agder', MuniName='Grimstad', Country='Norway', NorskNavn='taksvale'),\n",
       " Row(County='Trøndelag', MuniName='Levanger', Country='Norway', NorskNavn='stær'),\n",
       " Row(County='Trøndelag', MuniName='Ørland', Country='Norway', NorskNavn='storspove'),\n",
       " Row(County='Rogaland', MuniName='Stavanger', Country='Norway', NorskNavn='stær'),\n",
       " Row(County='Agder', MuniName='Farsund', Country='Norway', NorskNavn='sivspurv')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redlist.select([\"County\", \"MuniName\", \"Country\", \"NorskNavn\"]).take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data\n",
    "\n",
    "### Fix schema\n",
    "- make sure we have correct date formats\n",
    "- prepare for parallell etl\n",
    "    - include boto3 library\n",
    "    - list bucket keys\n",
    "    - read .csv table into redshift as is or prepartion tables in S3 as facts and dimensions\n",
    "    - create postgres facts and dimension tables in redshift\n",
    "    - insert data using copy command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the DataFrame as a SQL temporary view\n",
    "redlist.createOrReplaceTempView(\"redlist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|             SPECIES|   CNT|\n",
      "+--------------------+------+\n",
      "|         Larus canus|364333|\n",
      "|Somateria mollissima|300448|\n",
      "|    Sturnus vulgaris|266324|\n",
      "| Emberiza citrinella|253517|\n",
      "|Chroicocephalus r...|189492|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Which redlisted specieS are the most observed ones?\n",
    "species_observed = spark.sql(\"\"\"\n",
    "    SELECT SPECIES,\n",
    "           COUNT(*) AS CNT\n",
    "    FROM REDLIST\n",
    "    GROUP BY SPECIES\n",
    "    ORDER BY CNT DESC\n",
    "    limit 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|NUM_OF_SPECIES|\n",
      "+--------------+\n",
      "|          4075|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count distinct redlisted species observed\n",
    "num_of_species = spark.sql(\"\"\"\n",
    "    SELECT COUNT(DISTINCT SPECIES) AS NUM_OF_SPECIES\n",
    "    FROM REDLIST\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+\n",
      "|MONTHIDENTIFIED|    CNT|\n",
      "+---------------+-------+\n",
      "|              0|4215033|\n",
      "|              1|  23978|\n",
      "|             10|  15870|\n",
      "|             11|   5216|\n",
      "|             12|   3809|\n",
      "|              2|   3400|\n",
      "|              3|   2485|\n",
      "|              4|   4090|\n",
      "|              5|   9104|\n",
      "|              6|  20445|\n",
      "|              7|  23163|\n",
      "|              8|  29187|\n",
      "|              9|  28510|\n",
      "+---------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check how the observations are distributed on \"MonthIdentified\"\n",
    "dist_identified = spark.sql(\"\"\"\n",
    "\n",
    "    SELECT MONTHIDENTIFIED,\n",
    "           COUNT(*) AS CNT\n",
    "    FROM REDLIST\n",
    "    GROUP BY MONTHIDENTIFIED\n",
    "    ORDER BY MONTHIDENTIFIED ASC\n",
    "    \n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+\n",
      "|MONTHCOLLECTED|   CNT|\n",
      "+--------------+------+\n",
      "|             1|271527|\n",
      "|             2|182156|\n",
      "|             3|307859|\n",
      "|             4|544599|\n",
      "|             5|710578|\n",
      "|             6|532953|\n",
      "|             7|408897|\n",
      "|             8|460916|\n",
      "|             9|347744|\n",
      "|            10|302214|\n",
      "|            11|182210|\n",
      "|            12|132637|\n",
      "+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check how the observations are distributed on \"MonthCollected\"\n",
    "dist_identified = spark.sql(\"\"\"\n",
    "    -- Check how data is distributed on \"MonthCollected\"\n",
    "    SELECT MONTHCOLLECTED,\n",
    "           COUNT(*) AS CNT\n",
    "    FROM REDLIST\n",
    "    GROUP BY MONTHCOLLECTED\n",
    "    ORDER BY MONTHCOLLECTED ASC\n",
    "    \n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
